{"cells":[{"metadata":{"id":"3E438EBDC04044E6869A284F8F5A00F6","notebookId":"62569aa7231f0d0017312c85","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"from tensorflow.keras import backend as K\nimport os\nimport numpy as np\nimport random\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.models import Model,load_model\nfrom tensorflow.keras.layers import Input, Concatenate, Conv2D, MaxPooling2D, UpSampling2D, Dropout,BatchNormalization,ZeroPadding2D,add, Flatten,Activation,AveragePooling2D,Dense\nfrom tensorflow.keras.optimizers import Adam,SGD,RMSprop\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler,CSVLogger,ReduceLROnPlateau\nfrom tensorflow.keras.layers import Lambda\nfrom tensorflow.keras.preprocessing.image import img_to_array,ImageDataGenerator\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import plot_model,to_categorical\nimport h5py\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageEnhance, ImageOps, ImageFile\nimport time\nfrom all_model import all_model\nfrom utils import *\n# from historycal import LossHistory\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","execution_count":1},{"metadata":{"id":"A55C9C30872343CE8A2F2EBC12C9A7BB","notebookId":"62569aa7231f0d0017312c85","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"(5000, 256, 256, 3) (5000, 256, 256)\n(2000, 256, 256, 3) (2000, 256, 256, 6)\n","name":"stdout"}],"source":"hdf5_path = \"/home/nmic/input/nas5918/HJtest2-tf1/data/train_5000.hdf5\"\nfd = h5py.File(hdf5_path)\nimages,labels=fd['image'],fd['label']\nimages,labels=np.asarray(fd['image']),np.asarray(fd['label'])\nprint(images.shape,labels.shape)\nfd.close()\n\n# classes = np.unique(labels)  #标签类别\n# class_weight = compute_class_weight('balanced', classes, labels.ravel())\n# print(class_weight)\n# class_weight=[0.27993096,1.59620928,32.11132344,1.81175424,0.842855,31.57588407]\n\nn_label=6 #耕地=0，林地=1，草地=2，水域=3，居民地=4，未利用=5\nimg,msk = get_normalized_patches(images[:2000],labels[:2000],n_label)","execution_count":3},{"metadata":{"id":"DCC38212A6884D1E83659E27ED3E4438","notebookId":"62569aa7231f0d0017312c85","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"(1600, 256, 256, 3) (400, 256, 256, 3) (1600, 256, 256, 6) (400, 256, 256, 6)\n","name":"stdout"}],"source":"del images,labels\nxtrain,xtest,ytrain,ytest=train_test_split(img,msk,test_size=0.2,random_state=42)\ndel img,msk\nprint(xtrain.shape,xtest.shape,ytrain.shape,ytest.shape)","execution_count":4},{"metadata":{"id":"E46F40BC8E24455A98C2E4D6E8B2E89E","notebookId":"62569aa7231f0d0017312c85","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false,"hide_input":false},"cell_type":"code","outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 1800x360 with 20 Axes>","text/html":"<!- image uploading -->"}},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 1800x360 with 20 Axes>","text/html":"<!- image uploading -->"}}],"source":"plot_func(xtrain[40:, :, :, :], ytrain[40:, :, :, 0])","execution_count":5},{"metadata":{"id":"330FE8BD6777441BB20F1F71997596FC","notebookId":"62569aa7231f0d0017312c85","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"loss='categorical_crossentropy'#'categorical_crossentropy'#'binary_crossentropy'FocalLoss\noptimizer=Adam()#Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)#Adam()#SGD(),Adamax(),Adadelta()R\nloss_weights=''\nmetrics=['accuracy']\ninput_height=256\ninput_width=256\nbatch_size=10\nepoch=20\nnclass=n_label\nnchannel=xtrain.shape[-1]\nnum_train=xtrain.shape[0]\nnum_val=xtest.shape[0]\nATM=all_model(loss,loss_weights,optimizer,metrics,input_height,input_width,nclass,nchannel)","execution_count":6},{"metadata":{"id":"4469A7122D1E4D7995C7187BEF36A724","notebookId":"62569aa7231f0d0017312c85","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"2022-04-16 14:50:08.391509: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-04-16 14:50:08.948681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30981 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n","name":"stderr"}],"source":"nickname='UNET_VGG'\nmodel=ATM.UNET_VGG()#FCN8,UNET_VGG,UNET_MINI,SQUEESE_UNET,DEEPLABV3plus,CBRRNET,GFCpsp_xception","execution_count":7},{"metadata":{"id":"68527D2903934B8CB06BD2F11A1198C5","notebookId":"62569aa7231f0d0017312c85","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":true,"scrolled":false,"hide_input":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Epoch 1/20\n","name":"stdout"},{"output_type":"stream","text":"2022-04-16 14:50:19.234930: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n2022-04-16 14:50:19.669429: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n","name":"stderr"},{"output_type":"stream","text":"160/160 [==============================] - 29s 135ms/step - loss: 1.1737 - accuracy: 0.6022 - val_loss: 1.1307 - val_accuracy: 0.5683\nEpoch 2/20\n160/160 [==============================] - 22s 140ms/step - loss: 1.0648 - accuracy: 0.6037 - val_loss: 1.1383 - val_accuracy: 0.5684\nEpoch 3/20\n160/160 [==============================] - 22s 141ms/step - loss: 1.0523 - accuracy: 0.6134 - val_loss: 1.0428 - val_accuracy: 0.6019\nEpoch 4/20\n160/160 [==============================] - 21s 133ms/step - loss: 1.0135 - accuracy: 0.6275 - val_loss: 1.1161 - val_accuracy: 0.5951\nEpoch 5/20\n160/160 [==============================] - 22s 136ms/step - loss: 0.9894 - accuracy: 0.6406 - val_loss: 0.9820 - val_accuracy: 0.6351\nEpoch 6/20\n160/160 [==============================] - 20s 127ms/step - loss: 0.9961 - accuracy: 0.6370 - val_loss: 1.0103 - val_accuracy: 0.6163\nEpoch 7/20\n160/160 [==============================] - 22s 138ms/step - loss: 0.9721 - accuracy: 0.6448 - val_loss: 0.9704 - val_accuracy: 0.6400\nEpoch 8/20\n160/160 [==============================] - 22s 137ms/step - loss: 0.9644 - accuracy: 0.6505 - val_loss: 0.9600 - val_accuracy: 0.6374\nEpoch 9/20\n160/160 [==============================] - 21s 129ms/step - loss: 0.9906 - accuracy: 0.6426 - val_loss: 1.0076 - val_accuracy: 0.6170\nEpoch 10/20\n160/160 [==============================] - 20s 124ms/step - loss: 0.9718 - accuracy: 0.6445 - val_loss: 0.9976 - val_accuracy: 0.6205\nEpoch 11/20\n160/160 [==============================] - 20s 123ms/step - loss: 0.9657 - accuracy: 0.6421 - val_loss: 0.9719 - val_accuracy: 0.6302\nEpoch 12/20\n160/160 [==============================] - 20s 124ms/step - loss: 0.9585 - accuracy: 0.6510 - val_loss: 0.9623 - val_accuracy: 0.6429\nEpoch 13/20\n160/160 [==============================] - 22s 137ms/step - loss: 0.9481 - accuracy: 0.6531 - val_loss: 0.9576 - val_accuracy: 0.6379\nEpoch 14/20\n160/160 [==============================] - 21s 134ms/step - loss: 0.9349 - accuracy: 0.6546 - val_loss: 0.9433 - val_accuracy: 0.6471\nEpoch 15/20\n160/160 [==============================] - 21s 133ms/step - loss: 0.9182 - accuracy: 0.6649 - val_loss: 0.9342 - val_accuracy: 0.6558\nEpoch 16/20\n160/160 [==============================] - 20s 124ms/step - loss: 0.9455 - accuracy: 0.6555 - val_loss: 0.9633 - val_accuracy: 0.6465\nEpoch 17/20\n160/160 [==============================] - 20s 124ms/step - loss: 0.9243 - accuracy: 0.6610 - val_loss: 0.9378 - val_accuracy: 0.6497\nEpoch 18/20\n160/160 [==============================] - 21s 131ms/step - loss: 0.9215 - accuracy: 0.6619 - val_loss: 0.9327 - val_accuracy: 0.6475\nEpoch 19/20\n160/160 [==============================] - 21s 131ms/step - loss: 0.9139 - accuracy: 0.6641 - val_loss: 0.9189 - val_accuracy: 0.6551\nEpoch 20/20\n160/160 [==============================] - 20s 124ms/step - loss: 0.9155 - accuracy: 0.6664 - val_loss: 0.9446 - val_accuracy: 0.6500\ntime lapsing 431.71003556251526 s \n\n","name":"stdout"}],"source":"begin_time = time.time()\ncheckpoint_DIR = \"./checkpoint/\"\nif not os.path.exists(checkpoint_DIR):\n    os.makedirs(checkpoint_DIR)\nmodel_checkpoint = ModelCheckpoint(filepath=checkpoint_DIR + nickname + \"-{epoch:02d}e-val_loss{val_loss:2f}.hdf5\", monitor=\"val_loss\",save_best_only=True,mode='auto')\ncsvlogger = CSVLogger(filename=checkpoint_DIR +nickname +'-' +str(epoch) +'-log.csv', separator=',', append=False)\n# result=model.fit_generator(G1,verbose=1,steps_per_epoch=num_train/batch_size,epochs=epoch,validation_data=G2,validation_steps=num_val/batch_size,callbacks=[model_checkpoint,histories],shuffle=True )\n\nresult = model.fit(xtrain,ytrain,batch_size=batch_size,epochs=epoch,verbose=1,shuffle=True,validation_data=( xtest, ytest),callbacks=[ model_checkpoint, csvlogger])\nend_time = time.time()\nprint('time lapsing {0} s \\n'.format(end_time - begin_time))\n","execution_count":8},{"metadata":{"id":"BEEC59BA1A154AD0B27051506E1E7D5F","notebookId":"62569aa7231f0d0017312c85","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"display_data","metadata":{},"data":{"text/plain":"<Figure size 720x432 with 1 Axes>","text/html":"<!- image uploading -->"}}],"source":"def plot_fig(H,outdir):\n    N=len(result.history['loss'])\n    plt.style.use(\"ggplot\")\n    plt.figure(figsize=(10,6))\n    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n    plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n    plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n    plt.ylim(0,1)\n\n    plt.title(\"Training Loss and Accuracy\")\n    plt.xlabel(\"Epoch #\")\n    plt.ylabel(\"Loss/Accuracy\")\n    plt.legend(loc=\"lower left\")\n    plt.savefig(outdir)\nplot_fig(result,nickname+\"_Loss_Acc_epoch.png\")","execution_count":9},{"metadata":{"id":"D5D06A46D68F4D18AF0B9C57B321C710","notebookId":"62569aa7231f0d0017312c85","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<bound method File.close of <HDF5 file \"val-data-500.hdf5\" (mode r)>>"},"execution_count":2}],"source":"hdf5_path = '/home/nmic/input/nas5918/HJtest2-tf1/data/val-data-500.hdf5' \nfd = h5py.File(hdf5_path)\nfd.keys()\nxval,yval=np.asarray(fd['xval']),np.asarray(fd['yval'])\nfd.close","execution_count":2},{"metadata":{"id":"F68B85215419428082560E2198818D6A","notebookId":"62569aa7231f0d0017312c85","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"2022-04-16 15:06:50.969634: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-04-16 15:06:51.553735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30981 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n","name":"stderr"}],"source":"model=load_model('/home/nmic/project/checkpoint/UNET_VGG-19e-val_loss0.918906.hdf5')","execution_count":3},{"metadata":{"id":"1E7F75C4869546938D1830D0C61A6EBB","notebookId":"62569aa7231f0d0017312c85","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"2022-04-16 15:06:55.311978: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n2022-04-16 15:06:55.781083: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n","name":"stderr"},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 1800x360 with 20 Axes>","text/html":"<!- image uploading -->"}},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 1800x360 with 20 Axes>","text/html":"<!- image uploading -->"}},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 1800x360 with 20 Axes>","text/html":"<!- image uploading -->"}}],"source":"i=0\nn_label=6\nnickname='unet_vgg'\nresult=model.predict(xval/255.0,)\npred=np.argmax(result,axis=-1)\nnewy=label_hot(yval,n_label)\nval_plot_func(xval[i:i+20]/255.0,result[i:i+20,:,:,4],newy[i:i+20,:,:,4])\ni+=30\n#耕地=0，林地=1，草地=2，水域=3，居民地=4，未利用=5","execution_count":4},{"metadata":{"id":"FC3E5F1A80F64F19888F554E7F85E1AC","notebookId":"62569aa7231f0d0017312c85","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"          accuracy  precision    recall  F1-score       iou        oa  \\\ncrop      0.702031   0.881798  0.698143  0.779296  0.638399  0.662983   \ntree      0.913546   0.294729  0.676472  0.410576  0.258317  0.662983   \ngrass     0.993365   0.000000       NaN  0.000000  0.000000  0.662983   \nwater     0.900902   0.026655  0.640452  0.051179  0.026262  0.662983   \nbuilding  0.821745   0.551791  0.526484  0.538841  0.368776  0.662983   \nothers    0.994376   0.000000       NaN  0.000000  0.000000  0.662983   \nmean      0.887661   0.292495       NaN  0.296649  0.215292  0.662983   \n\n              miou     fwiou  \ncrop      0.215292  0.565594  \ntree      0.215292  0.565594  \ngrass     0.215292  0.565594  \nwater     0.215292  0.565594  \nbuilding  0.215292  0.565594  \nothers    0.215292  0.565594  \nmean      0.215292  0.565594  \n","name":"stdout"},{"output_type":"stream","text":"/home/nmic/project/utils.py:70: RuntimeWarning: invalid value encountered in true_divide\n  recall = TP/(TP+FN)\n","name":"stderr"}],"source":"cal_table=val_cal(yval, pred, './'+nickname+'_result.csv', if_show=True)","execution_count":5},{"metadata":{"id":"AF4D4BE7B2534A518BAC0CFD34543B33","notebookId":"62569aa7231f0d0017312c85","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}